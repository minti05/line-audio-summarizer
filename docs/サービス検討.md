# LINE audiomemo サービス選定・検討

文字起こし（Speech-to-Text）と要約（LLM）を行うためのAPIサービスの比較・検討結果をまとめます。
当初検討していたGemini, Whisperに加え、高速性やコストパフォーマンスに優れたDeepgramなども調査しました。

## 1. 料金・性能比較表 (2026年1月時点推定)

| サービス | 文字起こし料金 (1分あたり) | 要約料金 (LLM) | 特徴 | 日本語精度 | レスポンス速度 |プロバイダ |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| **OpenAI API**<br>(Whisper + GPT-4o) | **$0.006**<br>(約 0.9円) | GPT-4o mini: very cheap<br>GPT-4o: moderate | 定番の組み合わせ。<br>精度は非常に高い。<br>実装情報が豊富。 | ◎<br>非常に高い | ◯<br>標準的 | OpenAI |
| **Google Gemini**<br>(1.5 Flash) | **~$0.001〜**<br>(※1) | 文字起こしとセット<br>(マルチモーダル入力) | **音声データを直接入力して要約まで一発で可能。**<br>圧倒的な安さと構築のシンプルさ。 | ◯<br>高い<br>(要約向けなら十分) | ◎<br>非常に高速 | Google |
| **Deepgram**<br>(Nova-2) | **$0.0043**<br>(約 0.65円) | 別途LLMが必要 | **爆速文字起こし**と言えばこれ。<br>リアルタイム性に特化。<br>話者分離(Diarization)が得意。 | ◯<br>良好<br>(固有名詞に強い) | **◎+**<br>爆速 | Deepgram |
| **AssemblyAI** | **$0.0025**<br>(約 0.38円) | 別途LLMが必要<br>(Leopals等) | 非常に安価だが、話者分離などがOption料金。<br>要約機能もOptionであり。 | △〜◯<br>改善傾向 | ◯<br>標準的 | AssemblyAI |

*(※1) Gemini 1.5 Flashは100万トークンあたり$0.075(入力)。音声1分≒1,500トークン換算の場合、約$0.0001〜となり、他を圧倒する安さになる可能性があります（レートは変動するため要検証）。*

---

## 2. 各構成の詳細検討

### A案: Google Gemini 1.5 Flash (All-in-One構成)
音声を直接Geminiにアップロードし、「この音声を文字起こしして要約して」とプロンプトを送る構成です。

*   **メリット**:
    *   **開発工数が最小**: 文字起こしAPIと要約APIを分ける必要がない。
    *   **文脈理解**: 音声のトーンやニュアンスも含めてAIが理解できる（マルチモーダル）。
    *   **コスト**: 圧倒的に安い。無料枠（Google AI Studio等）も大きい。
    *   **速度**: 中間処理がないため、トータル処理時間は短い。
*   **デメリット**:
    *   **厳密な文字起こし**: 一言一句正確な「書き起こしテキスト」が欲しい場合、専用STTより劣る場合がある（要約用途なら問題なし）。
*   **LINE audiomemoへの適合度**: **SS (本命)**
    *   コスト、速度、実装の容易さ全ての面で今回の「個人の備忘録・ジャーナリング」用途に最適。

### B案: OpenAI Whisper API + GPT-4o mini
音声をWhisperでテキスト化し、そのテキストをGPTに投げて要約する構成です。

*   **メリット**:
    *   **安定性**: 文字起こしの精度が安定しており、誤字脱字が少ない。
    *   **柔軟性**: 文字起こし結果だけをObsidianに保存し、要約は別途生成するなど、中間データが扱いやすい。
*   **デメリット**:
    *   **コスト**: Gemini Flash構成に比べると割高。
    *   **速度**: 2段階のAPIコールが発生するため、ユーザーへのレスポンスが数秒遅れる可能性がある。
*   **LINE audiomemoへの適合度**: **S (対抗)**
    *   Geminiの音声認識精度に不満が出た場合の確実な代替案。

### C案: Deepgram + 高速LLM (Groq/Llama3等)
Deepgramで超高速に文字起こしをし、Groqなどの超高速推論LLMで要約する「速度特化」構成です。

*   **メリット**:
    *   **爆速**: ユーザーが送信してから結果が返るまでの体感速度が最速。
    *   **話者分離**: 「Aさん：〜、Bさん：〜」といった会話形式のメモを残したい場合に強力。
*   **デメリット**:
    *   **複雑**: 複数のサービスを契約・実装する必要がある。
    *   **コスト管理**: サービスごとの請求になるため管理が面倒。
*   **LINE audiomemoへの適合度**: **A (変化球)**
    *   インタビューの録音など「会話」をメインにするならありだが、自分一人のメモならオーバースペック気味。

## 3. 結論・推奨

**まずは「Google Gemini 1.5 Flash」単体での実装を推奨します。**

理由:
1.  **圧倒的なコストパフォーマンス**: 個人開発・運用においてランニングコストを気にせず使える。
2.  **マルチモーダル性能**: 「怒って言っている」「急いでいる」などのニュアンスも拾える可能性があり、感情ジャーナリングに適している。
3.  **シンプルさ**: コード量が減り、メンテナンスしやすい。

**次点**:
もしGeminiの日本語文字起こし精度（特に専門用語など）が低いと感じた場合は、**Deepgram (STT) + Gemini or GPT (LLM)** の構成に切り替えるのが良いでしょう。Whisper APIは安定していますが、Deepgramの方が安く高速なため、個人開発の「体験」としてはDeepgramの方が面白い選択肢になります。

### TODO: 検証項目
*   [ ] Gemini 1.5 Flashに、実際に日本語の雑な独り言（1分程度）を投げて、意図通りの要約が返ってくるかテストする。
*   [ ] Cloudflare WorkersからGemini API (Vertex AI or Google AI Studio) へのファイルアップロード・接続手順の確認。
